# OpenAI API Key - https://platform.openai.com/overview
OPENAI_API_KEY=

# change this to an `accessToken` extracted from the ChatGPT site's `https://chat.openai.com/api/auth/session` response
OPENAI_ACCESS_TOKEN=

# OpenAI API Base URL - https://api.openai.com
OPENAI_API_BASE_URL=

# OpenAI API Model - https://platform.openai.com/docs/models
OPENAI_API_MODEL=

# set `false` to enable OpenAI API debug log (disabled by default)
OPENAI_API_DISABLE_DEBUG=true

# Reverse Proxy - Available on accessToken
# Default: https://ai.fakeopen.com/api/conversation
# More: https://github.com/transitive-bullshit/chatgpt-api#reverse-proxy
API_REVERSE_PROXY=

# timeout
TIMEOUT_MS=100000

# timeout for usage billing query
USAGE_REQUEST_TIMEOUT_MS=10000

# Rate Limit
MAX_REQUEST_PER_HOUR=60

# Verify endpoint rate limit
MAX_VERIFY_PER_HOUR=20

# Max prompt length accepted by /chat-process
MAX_PROMPT_CHARS=32000

# Max system message length accepted by /chat-process
MAX_SYSTEM_MESSAGE_CHARS=8000

# Max verify token length accepted by /verify
MAX_VERIFY_TOKEN_CHARS=1024

# JSON body size limit for Express (e.g. 512kb, 1mb)
JSON_BODY_LIMIT=1mb

# Express trust proxy setting.
# Keep `false` when app is directly internet-facing.
# Set `1` when behind one trusted reverse proxy (e.g. ingress / nginx).
TRUST_PROXY=false

# Secret key
AUTH_SECRET_KEY=

# Require AUTH_SECRET_KEY in production (recommended)
AUTH_REQUIRED_IN_PRODUCTION=true

# Comma-separated CORS allowlist, e.g. http://localhost:1002,https://your-domain.com
CORS_ALLOW_ORIGIN=http://localhost:1002,http://127.0.0.1:1002

# Socks Proxy Host
SOCKS_PROXY_HOST=

# Socks Proxy Port
SOCKS_PROXY_PORT=

# Socks Proxy Username
SOCKS_PROXY_USERNAME=

# Socks Proxy Password
SOCKS_PROXY_PASSWORD=

# HTTPS PROXY
HTTPS_PROXY=

# ALL PROXY (fallback)
ALL_PROXY=
